{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import Xception\n",
    "import keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_dir = 'data/00_input/test/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_classifier(train_gt, train_img_dir, fast_train=False):    \n",
    "    names = os.listdir(train_img_dir)\n",
    "    df = pd.DataFrame({'filename':names})\n",
    "    df['class'] = [*map(lambda name: train_gt[name], df['filename'])]\n",
    "    batch_size=10\n",
    "    train_generator = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    ).flow_from_dataframe(\n",
    "        directory=train_img_dir,\n",
    "        dataframe=df,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='sparse',\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "    )\n",
    "\n",
    "    num_classes = 50\n",
    "    xception = Xception()\n",
    "    for layer in xception.layers: # first we optimize new layers only\n",
    "        layer.trainable = False\n",
    "\n",
    "    activation = xception.get_layer('block14_sepconv2_act').output\n",
    "    pool = L.GlobalMaxPooling2D()(activation)\n",
    "    dropout = L.Dropout(0.5)(pool)\n",
    "    dense = L.Dense(200, activation='relu')(dropout)\n",
    "    dense = L.Dense(num_classes, activation='softmax')(dense)\n",
    "    model = keras.models.Model(inputs=xception.inputs, outputs=dense)\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=0.001), \n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        metrics=['sparse_categorical_accuracy']\n",
    "    )\n",
    "    # localy this was done till convergence\n",
    "    model.fit_generator(train_generator, steps_per_epoch= 10, verbose=1)\n",
    "    \n",
    "    # now optimize whole model\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=0.0001), \n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        metrics=['sparse_categorical_accuracy']\n",
    "    )\n",
    "    \n",
    "    # localy this was done till convergence\n",
    "    model.fit_generator(train_generator, steps_per_epoch= 10, verbose=1)\n",
    "                      \n",
    "def classify(model, test_img_dir, batch_size=25):\n",
    "    names = os.listdir(test_img_dir)\n",
    "    df = pd.DataFrame({'names': names})\n",
    "    generator = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        x_col='names',\n",
    "        y_col=None,\n",
    "        directory=test_img_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        class_mode=None,\n",
    "    )\n",
    "    predicts = model.predict_generator(generator, steps=len(df.names) / batch_size, verbose=1)\n",
    "    return dict(zip(generator.filenames, map(np.argmax, predicts)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/00_input/train/gt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gt = dict(zip(df['filename'], df['class_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 images.\n",
      "100/100 [==============================] - 627s 6s/step\n"
     ]
    }
   ],
   "source": [
    "results = classify(model, test_img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 images belonging to 50 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 24s 2s/step - loss: 5.0210 - sparse_categorical_accuracy: 0.0400\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 95s 10s/step - loss: 4.2685 - sparse_categorical_accuracy: 0.0300\n"
     ]
    }
   ],
   "source": [
    "train_classifier(train_gt, test_img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['1321.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
