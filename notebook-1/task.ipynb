{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Склеивание панорам\n",
    "\n",
    "В данном задании нужно из нескольких кадров, снятых из одной точки, но под разными углами, составить одну панораму.\n",
    "Для этого мы будем использовать дескрипторы особых точек [ORB](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.370.4395&rep=rep1&type=pdf) и алгоритм оценки параметров модели [RANSAC](https://ru.wikipedia.org/wiki/RANSAC).\n",
    "\n",
    "На вход алгоритм получает N кадров.\n",
    "\n",
    "---\n",
    "Семинар:\n",
    "\n",
    "1. Находим особые точки и их дескрипторы на всех кадрах панорамы с помощью алгоритма ORB (можно использовать другой алгоритм). *1 балл*\n",
    "1. Получаем преобразование между соседними кадрами с помощью алгоритма ransac *1 балл*\n",
    "1. Получаем преобразование всех кадров на плоскость центрального кадра *2 балла*\n",
    "1. Преобразовываем кадры так, чтобы они оказались в плоскости центрального кадра и изображаем на одном изображении. *2 балла*\n",
    "\n",
    "---\n",
    "ДЗ: Смешиваем изображения с помощью лаплассовской пирамиды. *4 балла*\n",
    "\n",
    "Советы:\n",
    "- Для ускорения обработки можно уменьшить изображения в несколько раз после загрузки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Загрузка кадров\n",
    "\n",
    "В папке jpeg лежат подпапки 1, 2, 3, ...\n",
    "\n",
    "Каждая подпапка - набор кадров, которые вам предстоит склеить. Давайте откроем одну из папок и увидим, что у нее внутри."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGSIZE = (15, 10)\n",
    "COLUMNS = 3\n",
    "ROWS = 3\n",
    "\n",
    "def plot_collage(imgs, columns=COLUMNS, rows=ROWS, figsize=FIGSIZE, title=None):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(imgs[i-1], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pano_image_collection = io.ImageCollection('jpeg/lowres/8_*.jpg',\n",
    "                                           load_func=lambda f: io.imread(f).astype(np.float32) / 255)\n",
    "plot_collage(pano_image_collection, title=f\"Image collection size: {len(pano_image_collection)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Выделение ключевых точек (1 балл)\n",
    "\n",
    "Для начала найдем ключевые точки на каждом кадре.\n",
    "Если на последующих этапах качество совмещения будет недостаточным, настройте параметры алгоритма ORB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import ORB\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "def find_orb(img, n_keypoints=2000, **args):\n",
    "    \"\"\"Найти ключевые точки и их дескрипторы на изображении.\n",
    "    \n",
    "    img (np.array WxHx3) трехканальное изображение\n",
    "    n_keypoints (int) число ключевых точек, которые нужно найти на изображении\n",
    "    **kwargs (dict) остальные параметры, передаются в ORB без изменений\n",
    "    \n",
    "    Return: tuple (2,) координаты и дескриторы ключевых точек\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выводим первое изображение и ключевые точки на нем\n",
    "img = pano_image_collection[0]\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "\n",
    "keypoints, descriptors = find_orb(img)\n",
    "\n",
    "plt.scatter(keypoints[:, 1], keypoints[:, 0], facecolors='none', edgecolors='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Получаем преобразование между соседними кадрами с помощью алгоритма ransac (1 балл)\n",
    "\n",
    "На основе функции извлечения ключевых точек построим алгоритм поиска соответствий между соседними кадрами.\n",
    "\n",
    "Можно предполагать, что изображения размещены в порядке съемки слева направо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import match_descriptors\n",
    "from skimage.transform import ProjectiveTransform, AffineTransform\n",
    "from skimage.measure import ransac\n",
    "\n",
    "# Будем использовать дальше\n",
    "DEFAULT_TRANSFORM = ProjectiveTransform\n",
    "\n",
    "def find_robust_transform(src_keypoints, src_descriptors, dest_keypoints, dest_descriptors,\n",
    "                          return_matches=False,\n",
    "                          model_class=DEFAULT_TRANSFORM, min_samples=4, residual_threshold=1, \n",
    "                          max_trials=5000, **kwargs):\n",
    "    \"\"\"Найти соответствие между двумя кадрами панорамы.\n",
    "    \n",
    "    src_keypoints, dest_keypoints - координаты ключевых точек\n",
    "    src_descriptors, dest_descriptors - дескрипторы ключевых точек\n",
    "    model_class, min_samples, residual_threshold, **kwargs - параметры алгоритма ransac\n",
    "     - model_class - используемая модель преобразования плоскости\n",
    "     - min_samples - необходимое число точек для построения преобразования.\n",
    "                     Чем сложнее модель, тем больше нужно точек.\n",
    "                     Про конкретную модель можно прочитать в документации.\n",
    "     - residual_threshold - какое расстояние в пикселях между точками считать совпадением.\n",
    "     - max_trials - какое количество попыток можно сделать, прежде чем остановиться.\n",
    "                    Чем больше точек мы хотим сопоставить, тем больше должно быть это число.\n",
    "     - **kwargs - Остальные параметры\n",
    "     \n",
    "    \n",
    "    Return: tuple (2, )\n",
    "    result[0]: преобразование, переводящее 1 кадр в плоскость второго\n",
    "    result[1]: сопоставление точек (исключая выбросы)\n",
    "    \"\"\"\n",
    "    \n",
    "    # your code here   \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка работы функции поиска преобразований соседних кадров\n",
    "from skimage.feature import plot_matches\n",
    "\n",
    "src, dest = pano_image_collection[0], pano_image_collection[1]\n",
    "\n",
    "src_keypoints, src_descriptors = find_orb(src)\n",
    "dest_keypoints, dest_descriptors = find_orb(dest)\n",
    "\n",
    "robust_transform, matches = find_robust_transform(src_keypoints, src_descriptors, dest_keypoints, dest_descriptors, return_matches=True)\n",
    "\n",
    "# Visualize the results.\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "ax = plt.axes()\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(f\"Inlier correspondences: {len(matches)} points matched\")\n",
    "\n",
    "plot_matches(ax, src, dest, src_keypoints, dest_keypoints,\n",
    "             matches)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдем попарные преобразования между каждыми кадрами и сохраним в массив diff_warps\n",
    "keypoints, descriptors = zip(*(find_orb(img) for img in pano_image_collection))\n",
    "forward_transforms = tuple(find_robust_transform(src_kp, src_desc, dest_kp, dest_desc)\n",
    "                           for src_kp, src_desc, dest_kp, dest_desc \n",
    "                           in zip(keypoints[:-1], descriptors[:-1], keypoints[1:], descriptors[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Получаем преобразование всех кадров на плоскость центрального кадра (2 балла)\n",
    "\n",
    "Так как на крайних кадрах может не быть одинаковых объектов, нам придется сначала искать преобразование между соседними кадрами, а потом строить преобразование, которое каждый кадр приведет на плоскость среднего кадра.\n",
    "\n",
    "Hints:\n",
    "- Преобразования skimage можно складывать.\n",
    "- Первая строчка может вам понадобиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "def find_simple_center_warps(forward_transforms):\n",
    "    \"\"\"Найдем преобразование, которое каждый кадр коллекции приведет на плоскость среднего кадра.\n",
    "    diff_warps: Tuple[N] - попарные преобразования кадров\n",
    "    return List[N + 1] - преобразования каждого кадра в плоскость центрального кадра\n",
    "    \"\"\"\n",
    "    image_count = len(forward_transforms) + 1 # сколько всего изображений\n",
    "    center_index = (image_count - 1) // 2 # какой индекс у центральной картинки\n",
    "    \n",
    "    result = [None] * image_count\n",
    "    result[center_index] = DEFAULT_TRANSFORM()\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    return tuple(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "np.random.seed(0)\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "ax = plt.axes()\n",
    "\n",
    "def get_corners(image_collection, center_warps):\n",
    "    \"\"\"Получаем координаты углов каждого кадра после преобразований.\"\"\"\n",
    "    for img, transform in zip(pano_image_collection, center_warps):\n",
    "        height, width, _ = img.shape\n",
    "        corners = np.array([[0, 0],\n",
    "                            [height, 0],\n",
    "                            [height, width],\n",
    "                            [0, width]\n",
    "                           ])\n",
    "\n",
    "        yield transform(corners)[:, ::-1]\n",
    "\n",
    "def get_min_max_coords(corners):\n",
    "    \"\"\"Получаем минимальный и максимальные координаты углов.\"\"\"\n",
    "    corners = np.concatenate(corners)\n",
    "    return corners.min(axis=0), corners.max(axis=0)  \n",
    "\n",
    "# Проверка\n",
    "simple_center_warps = find_simple_center_warps(forward_transforms)\n",
    "corners = tuple(get_corners(pano_image_collection, simple_center_warps))\n",
    "\n",
    "for coords in corners:\n",
    "    ax.add_patch(Polygon(coords, closed=True, fill=False, color=np.random.rand(3)))\n",
    "\n",
    "min_coords, max_coords = get_min_max_coords(corners)\n",
    "plt.xlim(min_coords[0], max_coords[0])\n",
    "plt.ylim(max_coords[1], min_coords[1])\n",
    "\n",
    "center_index = (len(pano_image_collection) - 1) // 2\n",
    "plt.imshow(pano_image_collection[center_index])\n",
    "\n",
    "plt.title('Border visualization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, как мы видим, часть изображения ушла в отрицательную часть плоскости, а часть вышла за рамки центрального изображения. Если мы сейчас начнем соединять изображения, то все за рамками центрального изображения будет обрезано.\n",
    "\n",
    "Нам нужно:\n",
    "- Получить такие преобразования, которые отправляли бы изображение в положительную четверть.\n",
    "- Рассчитать размер финального изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_center_warps(image_collection, simple_center_warps):\n",
    "    # your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "plt.figure(figsize=(15, 5))\n",
    "ax = plt.axes()\n",
    "\n",
    "# Проверка\n",
    "final_center_warps, output_shape = get_final_center_warps(pano_image_collection, simple_center_warps)\n",
    "corners = tuple(get_corners(pano_image_collection, final_center_warps))\n",
    "\n",
    "for coords in corners:\n",
    "    ax.add_patch(Polygon(coords, closed=True, fill=False, color=np.random.rand(3)))\n",
    "\n",
    "plt.xlim(0, output_shape[1])\n",
    "plt.ylim(output_shape[0], 0)\n",
    "\n",
    "plt.title('Border visualization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Преобразовываем кадры так, чтобы они оказались в плоскости центрального кадра и соединяем на одном изображении (2 балла)\n",
    "Теперь пришло время слить все изображения в одну панораму.\n",
    "\n",
    "Для этого реализуйте функцию слияния двух фотографий: на вход вы получаете новый кадр и его маску, а также результат и его маску. Вам необходимо обновить результат и маску.\n",
    "\n",
    "Советы:\n",
    "- Обратите внимание, что мы поворачиваем матрицу преобразования, т.к. она рассчитывается в координатах xy, а работа с изображениями идет в координатах row:col (yx).\n",
    "- У функции warp есть параметр cval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import warp\n",
    "\n",
    "def rotate_transform_matrix(transform):\n",
    "    \"\"\"Сделаем так, чтобы трансформация считалась в координатах row:col.\"\"\"\n",
    "    matrix = transform.params[(1, 0, 2), :][:, (1, 0, 2)]\n",
    "    return type(transform)(matrix)\n",
    "\n",
    "def warp_image(image, transform, output_shape):\n",
    "    \"\"\"Применить преобразование к изображению и вернуть преобразованное изображение и маску.\n",
    "    \n",
    "    image: изображение для преобразования\n",
    "    transform: преобразование\n",
    "    output_shape: размер результата\n",
    "    \n",
    "    return: tuple (2, )\n",
    "        np.array (h, w, 3) преобразованное изображение\n",
    "        np.array (h, w) маска        \n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    pass\n",
    "\n",
    "def navy_merge_pano(image_collection, final_center_warps, output_shape):\n",
    "    \"\"\"Склеим панораму из нескольких изображений.\n",
    "    \n",
    "    image_collection: набор изображений для склеивания\n",
    "    final_center_warps: преобразования, которые переводят все кадры на плоскость центрального кадра\n",
    "    output_shape: размер панорамы\n",
    "    \n",
    "    return: np.array (*output_shape, 3) изображение, на котором совмещены все кадры.\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=FIGSIZE)\n",
    "\n",
    "result = navy_merge_pano(pano_image_collection, final_center_warps, output_shape)\n",
    "plt.imshow(result)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*конец семинара*\n",
    "\n",
    "---\n",
    "\n",
    "## 5. ДЗ: Смешиваем изображения с помощью лаплассовской пирамиды (4 балла)\n",
    "\n",
    "Можно заметить, что на границе кадров возникают черные линии, а объекты стыкуются неидеально.\n",
    "\n",
    "Для смешивания нескольких кадров можно применить лаплассову пирамиду. Давайте реализуем ее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "\n",
    "def get_gaussian_pyramid(image, n_layers=4, sigma=2):\n",
    "    \"\"\"Построить набор изображений, рекурсивно обработанный с помощью гауссианы.\n",
    "    \n",
    "    image: np.array (h, w, 3)\n",
    "    n_layers: количество слоев в пирамиде гауссиан\n",
    "    sigma: gaussian sigma\n",
    "    \n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    pass\n",
    "\n",
    "def get_laplassian_pyramid(image, n_layers=4, sigma=2):\n",
    "    \"\"\"Представить изображение в виде лаплассовской пирамиды.\n",
    "    \n",
    "    image: np.array (h, w, 3)\n",
    "    n_layers: количество слоев в пирамиде гауссиан\n",
    "    sigma: gaussian sigma\n",
    "    \n",
    "    return: tuple(n_layers, ) of np.array (h, w, 3) лаплассовская пирамида\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    pass\n",
    "\n",
    "def merge_laplassian_pyramid(gaussian_pyramid):\n",
    "    \"\"\"Собрать из пирамиды гауссиан исходное изображение.\n",
    "    \n",
    "    gauss_pyramid: tuple of np.array (h, w, 3)\n",
    "    return: np.array (h, w, 3) image\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = pano_image_collection[0]\n",
    "\n",
    "def increase_contrast(image_collection):\n",
    "    result = []\n",
    "    \n",
    "    for img in image_collection:\n",
    "        img = img.copy()\n",
    "        for i in range(img.shape[-1]):\n",
    "            img[:, :, i] -= img[:, :, i].min()\n",
    "            img[:, :, i] /= img[:, :, i].max()\n",
    "        result.append(img)\n",
    "    \n",
    "    return result\n",
    "\n",
    "gaussian_pyramid = get_laplassian_pyramid(img)\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Input image')\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Merged image')\n",
    "plt.axis('off')\n",
    "plt.imshow(merge_laplassian_pyramid(gaussian_pyramid))\n",
    "\n",
    "plot_collage(increase_contrast(gaussian_pyramid), columns=2, rows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_merge_pano(image_collection, final_center_warps, output_shape, n_layers=4, image_sigma=2, merge_sigma=10):\n",
    "    \"\"\"Склеим панораму из нескольких изображений.\n",
    "    Здесь нужно реализовать склеивание с использованием пирамиды гауссиан.\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=FIGSIZE)\n",
    "\n",
    "result = gaussian_merge_pano(pano_image_collection, final_center_warps, output_shape)\n",
    "plt.imshow(result)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем все вместе!\n",
    "def merge_pano(image_collection):\n",
    "    keypoints, descriptors = zip(*(find_orb(img) for img in image_collection))\n",
    "    forward_transforms = tuple(find_robust_transform(src_kp, src_desc, dest_kp, dest_desc)\n",
    "                               for src_kp, src_desc, dest_kp, dest_desc \n",
    "                               in zip(keypoints[:-1], descriptors[:-1], keypoints[1:], descriptors[1:]))\n",
    "    simple_center_warps = find_simple_center_warps(forward_transforms=forward_transforms)\n",
    "    final_center_warps, output_shape = get_final_center_warps(image_collection=image_collection, \n",
    "                                                              simple_center_warps=simple_center_warps)\n",
    "    return gaussian_merge_pano(image_collection=image_collection, \n",
    "                               final_center_warps=final_center_warps, \n",
    "                               output_shape=output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=FIGSIZE)\n",
    "\n",
    "result = merge_pano(pano_image_collection)\n",
    "plt.imshow(result)\n",
    "plt.axis('off')\n",
    "plt.imsave('result.png', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результат\n",
    "\n",
    "Результат своей работы вы можете скачать [по ссылке](result.png)\n",
    "\n",
    "## Дальнейшее развитие\n",
    "\n",
    "За рамками этого вводного занятия алгоритм склейки панорам можно развивать следующими способами:\n",
    "\n",
    "1. Для избежания искажений нужно написать свой класс преобразования, который выполняет не проективное преобразование, а проекцию на цилиндр или сферу. Нужно реализовать методы `__call__`, `estimate`, `inverse`, `__add__`. \n",
    "1. Для корректной обработки проекции на сферу нужно научиться находить соответствие между кадрами без заданного порядка. Если мы хотим снять и землю, и небо, и большой участок по горизонтали, то придется искать соответствие между кадрами.\n",
    "1. Цветокоррекция: на участках неба заметна граница между кадрами.\n",
    "\n",
    "### См. также\n",
    "\n",
    "- На странице [release](https://github.com/vslutov/panorama-public/releases) можно скачать фотографии в большом разрешении.\n",
    "- В папке [jpeg/lowres](jpeg/lowres) лежат еще фотографии, которые можно использовать для создания панорам. Попробуйте соеденить их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
